// =============================================================================
// FICHIER 1: ModerationLevel.java
// =============================================================================
package com.nexusai.moderation.model.enums;

/**
 * Niveaux de mod√©ration applicables selon le plan d'abonnement.
 * 
 * @author NexusAI Team
 * @version 1.0
 */
public enum ModerationLevel {
    /**
     * Mod√©ration stricte (FREE/STANDARD) - Bloque tout contenu sensible
     */
    STRICT,
    
    /**
     * Mod√©ration l√©g√®re (PREMIUM) - Permet certains contenus adultes
     */
    LIGHT,
    
    /**
     * Mod√©ration optionnelle (VIP+ avec KYC Level 3) - Minimal filtering
     */
    OPTIONAL;
    
    /**
     * D√©termine si ce niveau permet du contenu adulte explicite
     */
    public boolean allowsExplicitContent() {
        return this == OPTIONAL;
    }
    
    /**
     * D√©termine si ce niveau n√©cessite un consentement explicite
     */
    public boolean requiresConsent() {
        return this == OPTIONAL;
    }
}

// =============================================================================
// FICHIER 2: IncidentType.java
// =============================================================================
package com.nexusai.moderation.model.enums;

/**
 * Types d'incidents de mod√©ration d√©tectables.
 */
public enum IncidentType {
    SEXUAL_CONTENT,
    SEXUAL_MINORS,      // TOUJOURS bloqu√© - ill√©gal
    VIOLENCE,
    GRAPHIC_VIOLENCE,
    HATE_SPEECH,
    HARASSMENT,
    SELF_HARM,
    TERRORISM,          // TOUJOURS bloqu√© - ill√©gal
    SPAM,
    ILLEGAL_ACTIVITY,
    DISTRESS_DETECTED,  // D√©tresse psychologique
    OTHER
}

// =============================================================================
// FICHIER 3: Severity.java
// =============================================================================
package com.nexusai.moderation.model.enums;

/**
 * Niveau de s√©v√©rit√© d'un incident de mod√©ration.
 */
public enum Severity {
    LOW(1),
    MEDIUM(2),
    HIGH(3),
    CRITICAL(4);  // Contenu ill√©gal, escalade imm√©diate
    
    private final int level;
    
    Severity(int level) {
        this.level = level;
    }
    
    public int getLevel() {
        return level;
    }
    
    public boolean isCritical() {
        return this == CRITICAL;
    }
}

// =============================================================================
// FICHIER 4: ModerationIncident.java (Entity)
// =============================================================================
package com.nexusai.moderation.model.entity;

import com.nexusai.moderation.model.enums.*;
import jakarta.persistence.*;
import lombok.*;
import org.hibernate.annotations.JdbcTypeCode;
import org.hibernate.type.SqlTypes;

import java.time.LocalDateTime;
import java.util.Map;
import java.util.UUID;

/**
 * Entit√© repr√©sentant un incident de mod√©ration d√©tect√©.
 * 
 * Un incident est cr√©√© quand du contenu inappropri√© est d√©tect√©,
 * qu'il soit bloqu√© ou simplement signal√©.
 * 
 * @author NexusAI Team
 */
@Entity
@Table(name = "moderation_incidents", indexes = {
    @Index(name = "idx_user_id", columnList = "user_id"),
    @Index(name = "idx_status", columnList = "status"),
    @Index(name = "idx_severity", columnList = "severity"),
    @Index(name = "idx_created_at", columnList = "created_at")
})
@Data
@NoArgsConstructor
@AllArgsConstructor
@Builder
public class ModerationIncident {
    
    @Id
    @GeneratedValue(strategy = GenerationType.UUID)
    private UUID id;
    
    /**
     * ID de l'utilisateur concern√© par l'incident
     */
    @Column(name = "user_id", nullable = false)
    private UUID userId;
    
    /**
     * Type de contenu mod√©r√© (TEXT, IMAGE, VIDEO)
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "content_type", nullable = false, length = 50)
    private ContentType contentType;
    
    /**
     * Hash SHA-256 du contenu (pas le contenu lui-m√™me pour privacy)
     */
    @Column(name = "content_hash", length = 64)
    private String contentHash;
    
    /**
     * ID de la conversation (si applicable)
     */
    @Column(name = "conversation_id")
    private String conversationId;
    
    /**
     * ID du message (si applicable)
     */
    @Column(name = "message_id")
    private String messageId;
    
    /**
     * Type d'incident d√©tect√©
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "incident_type", nullable = false, length = 50)
    private IncidentType incidentType;
    
    /**
     * Niveau de s√©v√©rit√©
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "severity", nullable = false, length = 20)
    private Severity severity;
    
    /**
     * Score de confiance du mod√®le ML (0.0 - 1.0)
     */
    @Column(name = "confidence")
    private Double confidence;
    
    /**
     * Scores d√©taill√©s de mod√©ration (JSON)
     * Exemple: {"sexual": 0.85, "violence": 0.12, "hate": 0.03}
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "moderation_scores", columnDefinition = "jsonb")
    private Map<String, Double> moderationScores;
    
    /**
     * Statut de l'incident (PENDING, REVIEWED, DISMISSED, ESCALATED)
     */
    @Column(name = "status", nullable = false, length = 20)
    private String status = "PENDING";
    
    /**
     * Incident trait√© automatiquement par IA (true) ou par mod√©rateur humain (false)
     */
    @Column(name = "automated")
    private Boolean automated = true;
    
    /**
     * ID du mod√©rateur qui a review√© l'incident
     */
    @Column(name = "reviewed_by")
    private UUID reviewedBy;
    
    /**
     * Date de review par un mod√©rateur
     */
    @Column(name = "reviewed_at")
    private LocalDateTime reviewedAt;
    
    /**
     * Action prise suite √† l'incident (BLOCKED, WARNING_ISSUED, USER_BANNED, etc.)
     */
    @Column(name = "action_taken", length = 100)
    private String actionTaken;
    
    /**
     * Notes du mod√©rateur
     */
    @Column(name = "notes", columnDefinition = "TEXT")
    private String notes;
    
    /**
     * Date de cr√©ation de l'incident
     */
    @Column(name = "created_at", nullable = false)
    private LocalDateTime createdAt = LocalDateTime.now();
    
    @PrePersist
    protected void onCreate() {
        if (createdAt == null) {
            createdAt = LocalDateTime.now();
        }
    }
}

// =============================================================================
// FICHIER 5: ModerationRule.java (Entity)
// =============================================================================
package com.nexusai.moderation.model.entity;

import com.nexusai.moderation.model.enums.ModerationLevel;
import jakarta.persistence.*;
import lombok.*;

import java.time.LocalDateTime;
import java.util.UUID;

/**
 * R√®gle de mod√©ration d√©finissant les seuils et actions selon le niveau.
 * 
 * Permet de configurer dynamiquement le comportement de mod√©ration
 * sans recompiler l'application.
 * 
 * @author NexusAI Team
 */
@Entity
@Table(name = "moderation_rules", indexes = {
    @Index(name = "idx_level_category", columnList = "moderation_level, content_category")
})
@Data
@NoArgsConstructor
@AllArgsConstructor
@Builder
public class ModerationRule {
    
    @Id
    @GeneratedValue(strategy = GenerationType.UUID)
    private UUID id;
    
    /**
     * Niveau de mod√©ration (STRICT, LIGHT, OPTIONAL)
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "moderation_level", nullable = false, length = 20)
    private ModerationLevel moderationLevel;
    
    /**
     * Cat√©gorie de contenu concern√©e
     * Exemples: "sexual", "violence", "hate", "self-harm"
     */
    @Column(name = "content_category", nullable = false, length = 50)
    private String contentCategory;
    
    /**
     * Seuil de d√©clenchement (0.0 - 1.0)
     * Si le score ML > threshold, la r√®gle s'applique
     */
    @Column(name = "threshold", nullable = false)
    private Double threshold;
    
    /**
     * Action √† prendre: BLOCK, WARN, ALLOW
     */
    @Column(name = "action", nullable = false, length = 50)
    private String action;
    
    /**
     * R√®gle active (permet de d√©sactiver temporairement)
     */
    @Column(name = "active")
    private Boolean active = true;
    
    @Column(name = "created_at")
    private LocalDateTime createdAt = LocalDateTime.now();
    
    @Column(name = "updated_at")
    private LocalDateTime updatedAt = LocalDateTime.now();
    
    @PreUpdate
    protected void onUpdate() {
        updatedAt = LocalDateTime.now();
    }
}

// =============================================================================
// FICHIER 6: ModerationResponse.java (DTO)
// =============================================================================
package com.nexusai.moderation.model.dto;

import com.nexusai.moderation.model.enums.*;
import lombok.*;

import java.util.Map;

/**
 * R√©ponse du syst√®me de mod√©ration.
 * 
 * Indique si le contenu est accept√©, bloqu√© ou n√©cessite un avertissement.
 * 
 * @author NexusAI Team
 */
@Data
@NoArgsConstructor
@AllArgsConstructor
@Builder
public class ModerationResponse {
    
    /**
     * Contenu autoris√© (true) ou bloqu√© (false)
     */
    private boolean allowed;
    
    /**
     * Type d'incident d√©tect√© (null si aucun)
     */
    private IncidentType incidentType;
    
    /**
     * Niveau de s√©v√©rit√© (null si aucun incident)
     */
    private Severity severity;
    
    /**
     * Score de confiance (0.0 - 1.0)
     */
    private Double confidence;
    
    /**
     * Scores d√©taill√©s par cat√©gorie
     */
    private Map<String, Double> detailedScores;
    
    /**
     * Message explicatif pour l'utilisateur
     */
    private String message;
    
    /**
     * ID de l'incident cr√©√© (si applicable)
     */
    private String incidentId;
    
    /**
     * Avertissement √©mis (true/false)
     */
    private boolean warningIssued;
    
    /**
     * Factory method pour contenu autoris√©
     */
    public static ModerationResponse allowed() {
        return ModerationResponse.builder()
            .allowed(true)
            .message("Content approved")
            .build();
    }
    
    /**
     * Factory method pour contenu bloqu√©
     */
    public static ModerationResponse blocked(IncidentType type, Severity severity, String message) {
        return ModerationResponse.builder()
            .allowed(false)
            .incidentType(type)
            .severity(severity)
            .message(message)
            .build();
    }
}

// =============================================================================
// FICHIER 7: ModerationService.java (Interface)
// =============================================================================
package com.nexusai.moderation.service.moderation;

import com.nexusai.moderation.model.dto.ModerationResponse;

/**
 * Service principal de mod√©ration.
 * 
 * Interface unifi√©e pour mod√©rer tout type de contenu.
 * Les impl√©mentations sp√©cifiques g√®rent texte, images et vid√©os.
 * 
 * @author NexusAI Team
 */
public interface ModerationService {
    
    /**
     * Mod√®re du contenu textuel.
     * 
     * @param content Le texte √† mod√©rer
     * @param userId ID de l'utilisateur
     * @param conversationId ID de la conversation (optionnel)
     * @return R√©sultat de la mod√©ration
     */
    ModerationResponse moderateText(String content, String userId, String conversationId);
    
    /**
     * Mod√®re une image.
     * 
     * @param imageUrl URL de l'image √† mod√©rer
     * @param userId ID de l'utilisateur
     * @return R√©sultat de la mod√©ration
     */
    ModerationResponse moderateImage(String imageUrl, String userId);
    
    /**
     * Mod√®re une vid√©o.
     * 
     * @param videoUrl URL de la vid√©o √† mod√©rer
     * @param userId ID de l'utilisateur
     * @return R√©sultat de la mod√©ration
     */
    ModerationResponse moderateVideo(String videoUrl, String userId);
}

// =============================================================================
// FICHIER 8: TextModerationService.java (Impl√©mentation)
// =============================================================================
package com.nexusai.moderation.service.moderation;

import com.nexusai.moderation.model.dto.ModerationResponse;
import com.nexusai.moderation.model.entity.ModerationIncident;
import com.nexusai.moderation.model.entity.ModerationRule;
import com.nexusai.moderation.model.enums.*;
import com.nexusai.moderation.repository.ModerationIncidentRepository;
import com.nexusai.moderation.service.client.OpenAIModerationClient;
import com.nexusai.moderation.service.client.UserServiceClient;
import com.nexusai.moderation.service.detection.DistressDetectionService;
import com.nexusai.moderation.util.ContentHashUtil;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;

/**
 * Service de mod√©ration pour contenu textuel.
 * 
 * Workflow:
 * 1. D√©terminer niveau de mod√©ration utilisateur
 * 2. Pr√©-filtrage avec blacklist
 * 3. Analyse IA (OpenAI Moderation)
 * 4. Application des r√®gles
 * 5. D√©tection de d√©tresse (toujours actif)
 * 6. Cr√©ation incident si n√©cessaire
 * 
 * @author NexusAI Team
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class TextModerationService {
    
    private final OpenAIModerationClient openAIClient;
    private final UserServiceClient userServiceClient;
    private final ModerationRulesService rulesService;
    private final DistressDetectionService distressDetectionService;
    private final ModerationIncidentRepository incidentRepository;
    private final BlacklistService blacklistService;
    
    /**
     * Mod√®re un texte en appliquant toutes les r√®gles.
     * 
     * @param content Le contenu textuel √† mod√©rer
     * @param userId ID de l'utilisateur (UUID en String)
     * @param conversationId ID de la conversation (peut √™tre null)
     * @return R√©sultat de mod√©ration
     */
    @Transactional
    public ModerationResponse moderateText(String content, String userId, String conversationId) {
        log.info("Moderating text for user: {}, conversation: {}", userId, conversationId);
        
        // 1. D√©terminer niveau de mod√©ration
        ModerationLevel level = getUserModerationLevel(userId);
        log.debug("User moderation level: {}", level);
        
        // 2. Pr√©-filtrage blacklist (rapide)
        if (blacklistService.containsBlacklistedTerms(content)) {
            log.warn("Blacklisted term detected for user: {}", userId);
            return handleBlacklistViolation(content, userId, conversationId);
        }
        
        // 3. Analyse IA
        Map<String, Double> aiScores = openAIClient.moderate(content);
        log.debug("AI moderation scores: {}", aiScores);
        
        // 4. Appliquer r√®gles selon niveau
        ModerationDecision decision = applyRules(level, aiScores, content);
        
        // 5. D√©tection d√©tresse (TOUJOURS actif, m√™me pour VIP+)
        if (distressDetectionService.detectDistress(content, aiScores)) {
            log.warn("Distress detected for user: {}", userId);
            distressDetectionService.handleDistress(userId, conversationId);
            // Continue la mod√©ration normale en parall√®le
        }
        
        // 6. Si bloqu√©, cr√©er incident
        if (decision.isBlocked()) {
            ModerationIncident incident = createIncident(
                userId, 
                conversationId, 
                content, 
                decision,
                aiScores
            );
            
            return ModerationResponse.blocked(
                decision.getIncidentType(),
                decision.getSeverity(),
                decision.getMessage()
            ).toBuilder()
                .incidentId(incident.getId().toString())
                .detailedScores(aiScores)
                .confidence(decision.getConfidence())
                .build();
        }
        
        // 7. Si warning
        if (decision.isWarning()) {
            return ModerationResponse.builder()
                .allowed(true)
                .warningIssued(true)
                .message(decision.getMessage())
                .detailedScores(aiScores)
                .build();
        }
        
        // 8. Contenu autoris√©
        return ModerationResponse.allowed();
    }
    
    /**
     * D√©termine le niveau de mod√©ration applicable √† l'utilisateur.
     * 
     * Logique:
     * - FREE/STANDARD ‚Üí STRICT (forc√©)
     * - PREMIUM ‚Üí STRICT ou LIGHT (choix utilisateur)
     * - VIP+ ‚Üí OPTIONAL si KYC Level 3 + consentement actif
     * 
     * @param userId ID utilisateur
     * @return Niveau de mod√©ration
     */
    private ModerationLevel getUserModerationLevel(String userId) {
        // Appel au User Service pour r√©cup√©rer plan et pr√©f√©rences
        var userInfo = userServiceClient.getUserInfo(userId);
        var subscription = userInfo.getSubscription();
        
        // FREE/STANDARD ‚Üí STRICT (non n√©gociable)
        if (subscription.isFreeOrStandard()) {
            return ModerationLevel.STRICT;
        }
        
        // PREMIUM ‚Üí Choix utilisateur entre STRICT et LIGHT
        if (subscription.isPremium()) {
            return userInfo.getPreferences().getModerationLevel();
        }
        
        // VIP+ ‚Üí V√©rifier KYC + consentement
        if (subscription.isVipPlus()) {
            boolean hasKyc = userServiceClient.hasValidKYC(userId, 3);
            boolean hasConsent = userServiceClient.hasActiveConsent(userId, "UNMODERATED_MODE");
            
            if (hasKyc && hasConsent) {
                return ModerationLevel.OPTIONAL;
            }
        }
        
        // Par d√©faut: LIGHT
        return ModerationLevel.LIGHT;
    }
    
    /**
     * Applique les r√®gles de mod√©ration selon le niveau et les scores IA.
     * 
     * @param level Niveau de mod√©ration
     * @param aiScores Scores d'analyse IA
     * @param content Contenu original (pour analyse compl√©mentaire)
     * @return D√©cision de mod√©ration
     */
    private ModerationDecision applyRules(
            ModerationLevel level, 
            Map<String, Double> aiScores,
            String content) {
        
        // R√®gles CRITIQUES: TOUJOURS appliqu√©es, quel que soit le niveau
        
        // 1. Contenu p√©dopornographique (CSAM) - Z√âRO TOL√âRANCE
        Double csam Score = aiScores.getOrDefault("sexual/minors", 0.0);
        if (csamScore > 0.01) {  // Seuil ultra-bas
            log.error("CRITICAL: CSAM content detected! Score: {}", csamScore);
            return ModerationDecision.block(
                IncidentType.SEXUAL_MINORS,
                Severity.CRITICAL,
                "Contenu ill√©gal d√©tect√©. Votre compte a √©t√© signal√© aux autorit√©s.",
                csamScore
            );
        }
        
        // 2. Terrorisme - Z√âRO TOL√âRANCE
        Double terrorismScore = aiScores.getOrDefault("terrorism", 0.0);
        if (terrorismScore > 0.1) {
            log.error("CRITICAL: Terrorism content detected! Score: {}", terrorismScore);
            return ModerationDecision.block(
                IncidentType.TERRORISM,
                Severity.CRITICAL,
                "Contenu ill√©gal d√©tect√©.",
                terrorismScore
            );
        }
        
        // 3. Appliquer r√®gles configurables selon niveau
        List<ModerationRule> rules = rulesService.getRulesForLevel(level);
        
        for (ModerationRule rule : rules) {
            String category = rule.getContentCategory();
            Double score = aiScores.getOrDefault(category, 0.0);
            
            if (score > rule.getThreshold()) {
                log.debug("Rule triggered: {} (score: {} > threshold: {})", 
                    category, score, rule.getThreshold());
                
                return switch (rule.getAction()) {
                    case "BLOCK" -> ModerationDecision.block(
                        mapCategoryToIncidentType(category),
                        determineSeverity(score),
                        "Contenu inappropri√© d√©tect√©: " + category,
                        score
                    );
                    case "WARN" -> ModerationDecision.warn(
                        category,
                        "Attention: ce contenu pourrait enfreindre nos r√®gles",
                        score
                    );
                    default -> null; // ALLOW, continuer les v√©rifications
                };
            }
        }
        
        // Aucune r√®gle d√©clench√©e ‚Üí Contenu OK
        return ModerationDecision.allow();
    }
    
    /**
     * Cr√©e un incident de mod√©ration dans la base de donn√©es.
     */
    private ModerationIncident createIncident(
            String userId,
            String conversationId,
            String content,
            ModerationDecision decision,
            Map<String, Double> aiScores) {
        
        ModerationIncident incident = ModerationIncident.builder()
            .userId(UUID.fromString(userId))
            .contentType(ContentType.TEXT)
            .contentHash(ContentHashUtil.sha256(content))
            .conversationId(conversationId)
            .incidentType(decision.getIncidentType())
            .severity(decision.getSeverity())
            .confidence(decision.getConfidence())
            .moderationScores(aiScores)
            .status("PENDING")
            .automated(true)
            .actionTaken("BLOCKED")
            .build();
        
        return incidentRepository.save(incident);
    }
    
    /**
     * G√®re une violation de la blacklist.
     */
    private ModerationResponse handleBlacklistViolation(
            String content, 
            String userId, 
            String conversationId) {
        
        ModerationIncident incident = ModerationIncident.builder()
            .userId(UUID.fromString(userId))
            .contentType(ContentType.TEXT)
            .contentHash(ContentHashUtil.sha256(content))
            .conversationId(conversationId)
            .incidentType(IncidentType.HATE_SPEECH)
            .severity(Severity.HIGH)
            .confidence(1.0)
            .status("PENDING")
            .automated(true)
            .actionTaken("BLOCKED")
            .build();
        
        incidentRepository.save(incident);
        
        return ModerationResponse.blocked(
            IncidentType.HATE_SPEECH,
            Severity.HIGH,
            "Terme interdit d√©tect√© dans votre message."
        );
    }
    
    /**
     * Mappe une cat√©gorie de mod√©ration vers un IncidentType.
     */
    private IncidentType mapCategoryToIncidentType(String category) {
        return switch (category.toLowerCase()) {
            case "sexual", "sexual/explicit" -> IncidentType.SEXUAL_CONTENT;
            case "sexual/minors" -> IncidentType.SEXUAL_MINORS;
            case "violence", "violence/graphic" -> IncidentType.VIOLENCE;
            case "hate" -> IncidentType.HATE_SPEECH;
            case "self-harm" -> IncidentType.SELF_HARM;
            case "terrorism" -> IncidentType.TERRORISM;
            default -> IncidentType.OTHER;
        };
    }
    
    /**
     * D√©termine la s√©v√©rit√© en fonction du score.
     */
    private Severity determineSeverity(double score) {
        if (score >= 0.9) return Severity.CRITICAL;
        if (score >= 0.7) return Severity.HIGH;
        if (score >= 0.4) return Severity.MEDIUM;
        return Severity.LOW;
    }
}

// =============================================================================
// FICHIER 9: ModerationDecision.java (Helper Class)
// =============================================================================
package com.nexusai.moderation.service.moderation;

import com.nexusai.moderation.model.enums.*;
import lombok.*;

/**
 * Classe interne repr√©sentant une d√©cision de mod√©ration.
 * 
 * @author NexusAI Team
 */
@Data
@Builder
public class ModerationDecision {
    private boolean blocked;
    private boolean warning;
    private IncidentType incidentType;
    private Severity severity;
    private String message;
    private Double confidence;
    
    public static ModerationDecision allow() {
        return ModerationDecision.builder()
            .blocked(false)
            .warning(false)
            .build();
    }
    
    public static ModerationDecision block(
            IncidentType type, 
            Severity severity, 
            String message,
            Double confidence) {
        return ModerationDecision.builder()
            .blocked(true)
            .incidentType(type)
            .severity(severity)
            .message(message)
            .confidence(confidence)
            .build();
    }
    
    public static ModerationDecision warn(
            String category, 
            String message,
            Double confidence) {
        return ModerationDecision.builder()
            .blocked(false)
            .warning(true)
            .message(message)
            .confidence(confidence)
            .build();
    }
}

// =============================================================================
// FICHIER 10: DistressDetectionService.java
// =============================================================================
package com.nexusai.moderation.service.detection;

import com.nexusai.moderation.event.ModerationEventPublisher;
import com.nexusai.moderation.event.events.DistressDetectedEvent;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.util.*;
import java.util.regex.Pattern;

/**
 * Service de d√©tection de d√©tresse psychologique.
 * 
 * D√©tecte les signes de:
 * - Pens√©es suicidaires
 * - Auto-mutilation
 * - D√©tresse √©motionnelle s√©v√®re
 * 
 * IMPORTANT: Toujours actif, m√™me pour utilisateurs VIP+ avec mod√©ration minimale.
 * 
 * @author NexusAI Team
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class DistressDetectionService {
    
    private final ModerationEventPublisher eventPublisher;
    private final NotificationService notificationService;
    
    // Patterns de d√©tection (en production, utiliser un mod√®le ML)
    private static final List<Pattern> SUICIDAL_PATTERNS = Arrays.asList(
        Pattern.compile("\\b(je veux mourir|envie de mourir)\\b", Pattern.CASE_INSENSITIVE),
        Pattern.compile("\\b(me suicider|suicide|suicider)\\b", Pattern.CASE_INSENSITIVE),
        Pattern.compile("\\b(mettre fin √† mes jours|en finir)\\b", Pattern.CASE_INSENSITIVE),
        Pattern.compile("\\b(plus envie de vivre|ne plus vivre)\\b", Pattern.CASE_INSENSITIVE)
    );
    
    /**
     * D√©tecte des signes de d√©tresse dans un texte.
     * 
     * @param content Contenu √† analyser
     * @param moderationScores Scores de mod√©ration IA
     * @return true si d√©tresse d√©tect√©e
     */
    public boolean detectDistress(String content, Map<String, Double> moderationScores) {
        // 1. V√©rifier score self-harm de l'IA
        Double selfHarmScore = moderationScores.getOrDefault("self-harm", 0.0);
        if (selfHarmScore > 0.3) {
            log.warn("High self-harm score detected: {}", selfHarmScore);
            return true;
        }
        
        // 2. Analyse par patterns
        String lowerContent = content.toLowerCase();
        for (Pattern pattern : SUICIDAL_PATTERNS) {
            if (pattern.matcher(lowerContent).find()) {
                log.warn("Suicidal pattern detected: {}", pattern.pattern());
                return true;
            }
        }
        
        return false;
    }
    
    /**
     * G√®re la d√©tection de d√©tresse: notification + ressources.
     * 
     * @param userId ID utilisateur
     * @param conversationId ID conversation
     */
    public void handleDistress(String userId, String conversationId) {
        log.info("Handling distress for user: {}", userId);
        
        // 1. √âmettre √©v√©nement Kafka pour alerter mod√©rateurs
        eventPublisher.publishDistressDetected(
            new DistressDetectedEvent(userId, conversationId)
        );
        
        // 2. Envoyer message empathique imm√©diat
        String empathyMessage = buildEmpathyMessage();
        notificationService.sendSystemMessage(userId, conversationId, empathyMessage);
        
        // 3. Envoyer ressources d'aide
        String helpResourcesMessage = buildHelpResourcesMessage();
        notificationService.sendSystemMessage(userId, conversationId, helpResourcesMessage);
        
        // 4. Notification √©quipe support (si disponible)
        notificationService.alertSupportTeam(userId, "DISTRESS_DETECTED");
    }
    
    /**
     * Construit un message empathique.
     */
    private String buildEmpathyMessage() {
        return """
            Je remarque que vous traversez peut-√™tre un moment difficile.
            
            Sachez que vous n'√™tes pas seul(e). Il existe des personnes qualifi√©es 
            qui peuvent vous aider et vous √©couter, 24h/24 et 7j/7.
            
            Votre bien-√™tre est important. üíô
            """;
    }
    
    /**
     * Construit un message avec les ressources d'aide.
     */
    private String buildHelpResourcesMessage() {
        return """
            **Ressources d'aide imm√©diate:**
            
            üá´üá∑ France:
            - SOS Suicide Ph√©nix: 01 40 44 46 45
            - Suicide √âcoute: 01 45 39 40 00
            - SOS Amiti√©: 09 72 39 40 50
            
            üåç International:
            - Ligne d'√©coute 24/7: findahelpline.com
            
            üÜò Urgence: Appelez le 15 (SAMU) ou le 112
            
            N'h√©sitez pas √† en parler √† un proche de confiance ou √† consulter 
            un professionnel de sant√©.
            """;
    }
}

// =============================================================================
// FICHIER 11: ModerationController.java
// =============================================================================
package com.nexusai.moderation.controller;

import com.nexusai.moderation.model.dto.*;
import com.nexusai.moderation.service.moderation.TextModerationService;
import io.swagger.v3.oas.annotations.Operation;
import io.swagger.v3.oas.annotations.tags.Tag;
import jakarta.validation.Valid;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.ResponseEntity;
import org.springframework.security.access.prepost.PreAuthorize;
import org.springframework.security.core.annotation.AuthenticationPrincipal;
import org.springframework.web.bind.annotation.*;

/**
 * Contr√¥leur REST pour les op√©rations de mod√©ration.
 * 
 * @author NexusAI Team
 */
@RestController
@RequestMapping("/api/v1/moderation")
@RequiredArgsConstructor
@Slf4j
@Tag(name = "Moderation", description = "Content moderation APIs")
public class ModerationController {
    
    private final TextModerationService textModerationService;
    
    /**
     * Mod√®re du contenu textuel.
     * 
     * @param request Requ√™te de mod√©ration
     * @param userId ID utilisateur (extrait du JWT)
     * @return R√©sultat de mod√©ration
     */
    @PostMapping("/text")
    @PreAuthorize("hasAnyRole('USER', 'MODERATOR', 'ADMIN')")
    @Operation(summary = "Moderate text content")
    public ResponseEntity<ModerationResponse> moderateText(
            @Valid @RequestBody ModerationRequest request,
            @AuthenticationPrincipal String userId) {
        
        log.info("Moderation request for user: {}", userId);
        
        ModerationResponse response = textModerationService.moderateText(
            request.getContent(),
            userId,
            request.getConversationId()
        );
        
        return ResponseEntity.ok(response);
    }
}

// =============================================================================
// FIN DU CODE
// =============================================================================

/**
 * NOTES D'IMPL√âMENTATION:
 * 
 * 1. Services manquants √† impl√©menter:
 *    - OpenAIModerationClient (client HTTP vers OpenAI)
 *    - UserServiceClient (Feign client vers User Service)
 *    - BlacklistService (gestion blacklist)
 *    - NotificationService (envoi notifications)
 *    - ModerationRulesService (gestion r√®gles)
 * 
 * 2. Repositories √† cr√©er:
 *    - ModerationIncidentRepository extends JpaRepository
 *    - ModerationRuleRepository extends JpaRepository
 * 
 * 3. Configuration:
 *    - application.yml (DB, Kafka, APIs externes)
 *    - SecurityConfig.java (JWT authentication)
 *    - KafkaConfig.java (topics, producers, consumers)
 * 
 * 4. Tests:
 *    - TextModerationServiceTest (tests unitaires)
 *    - ModerationIntegrationTest (tests int√©gration)
 *    - DistressDetectionServiceTest
 * 
 * 5. Migration DB:
 *    - V1__create_moderation_tables.sql
 *    - V2__insert_default_rules.sql
 */
