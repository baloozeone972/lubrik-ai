# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MODULE 10 : ANALYTICS & MONITORING - DOCKER COMPOSE
# 
# Configuration Docker Compose pour l'environnement de dÃ©veloppement
# du module Analytics.
# 
# Services inclus :
# - ClickHouse (base de donnÃ©es analytics)
# - Kafka & Zookeeper (bus de messages)
# - Prometheus (mÃ©triques)
# - Grafana (dashboards)
# - Alertmanager (alertes)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

version: '3.8'

services:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # CLICKHOUSE - Base de donnÃ©es analytics
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  clickhouse:
    image: clickhouse/clickhouse-server:23.8-alpine
    container_name: nexusai-clickhouse
    hostname: clickhouse
    ports:
      - "8123:8123"  # HTTP interface
      - "9000:9000"  # Native client
    environment:
      CLICKHOUSE_DB: nexusai
      CLICKHOUSE_USER: nexusai
      CLICKHOUSE_PASSWORD: nexusai123
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./sql/init-clickhouse.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - nexusai-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # KAFKA & ZOOKEEPER - Bus de messages
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: nexusai-zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - nexusai-network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: nexusai-kafka
    hostname: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - nexusai-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # PROMETHEUS - Collecte de mÃ©triques
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: nexusai-prometheus
    hostname: prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/alerts.yml:/etc/prometheus/alerts.yml
      - prometheus_data:/prometheus
    networks:
      - nexusai-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ALERTMANAGER - Gestion des alertes
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: nexusai-alertmanager
    hostname: alertmanager
    ports:
      - "9093:9093"
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/config.yml
      - alertmanager_data:/alertmanager
    networks:
      - nexusai-network

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # GRAFANA - Dashboards & Visualisations
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  grafana:
    image: grafana/grafana:10.1.5
    container_name: nexusai-grafana
    hostname: grafana
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin123
      GF_INSTALL_PLUGINS: grafana-clickhouse-datasource
      GF_SERVER_ROOT_URL: http://localhost:3000
      GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH: /var/lib/grafana/dashboards/overview.json
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - ./monitoring/grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
      - ./monitoring/grafana/dashboards.yml:/etc/grafana/provisioning/dashboards/dashboards.yml
    networks:
      - nexusai-network
    depends_on:
      - prometheus
      - clickhouse

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # REDIS - Cache pour Analytics API
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  redis:
    image: redis:7-alpine
    container_name: nexusai-redis
    hostname: redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - nexusai-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ANALYTICS API - Service principal
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  analytics-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: nexusai-analytics-api
    hostname: analytics-api
    ports:
      - "8080:8080"
    environment:
      SPRING_PROFILES_ACTIVE: docker
      
      # ClickHouse
      CLICKHOUSE_URL: jdbc:clickhouse://clickhouse:8123/nexusai
      CLICKHOUSE_USER: nexusai
      CLICKHOUSE_PASSWORD: nexusai123
      
      # Kafka
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      
      # Redis
      REDIS_HOST: redis
      REDIS_PORT: 6379
      
      # Java Options
      JAVA_OPTS: -Xmx1g -Xms512m
    depends_on:
      clickhouse:
        condition: service_healthy
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - nexusai-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VOLUMES - Persistance des donnÃ©es
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
volumes:
  clickhouse_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local
  prometheus_data:
    driver: local
  alertmanager_data:
    driver: local
  grafana_data:
    driver: local
  redis_data:
    driver: local

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NETWORK - RÃ©seau partagÃ©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
networks:
  nexusai-network:
    driver: bridge

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROMETHEUS CONFIGURATION
# Fichier: monitoring/prometheus.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'nexusai-dev'
    environment: 'development'

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

# Load rules once and periodically evaluate them
rule_files:
  - 'alerts.yml'

# Scrape configurations
scrape_configs:
  # Analytics API
  - job_name: 'analytics-api'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['analytics-api:8080']
        labels:
          service: 'analytics-api'
          module: 'analytics'

  # Prometheus self-monitoring
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Kafka JMX metrics (optionnel)
  - job_name: 'kafka'
    static_configs:
      - targets: ['kafka:9092']

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ALERTMANAGER CONFIGURATION
# Fichier: monitoring/alertmanager.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

global:
  resolve_timeout: 5m

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'
  routes:
    - match:
        severity: critical
      receiver: 'critical'
      continue: true
    - match:
        severity: warning
      receiver: 'warning'

receivers:
  - name: 'default'
    webhook_configs:
      - url: 'http://analytics-api:8080/api/v1/analytics/webhooks/alerts'
  
  - name: 'critical'
    # Configuration Slack pour alertes critiques
    # slack_configs:
    #   - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    #     channel: '#alerts-critical'
    #     title: 'ğŸš¨ Critical Alert'
    
    # Configuration Email
    # email_configs:
    #   - to: 'ops@nexusai.com'
    #     from: 'alerts@nexusai.com'
    #     smarthost: 'smtp.gmail.com:587'
  
  - name: 'warning'
    # Configuration pour warnings
    webhook_configs:
      - url: 'http://analytics-api:8080/api/v1/analytics/webhooks/alerts'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'cluster', 'service']

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GRAFANA DATASOURCES
# Fichier: monitoring/grafana/datasources.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true

  - name: ClickHouse
    type: grafana-clickhouse-datasource
    access: proxy
    url: http://clickhouse:8123
    database: nexusai
    basicAuth: true
    basicAuthUser: nexusai
    secureJsonData:
      basicAuthPassword: nexusai123
    jsonData:
      defaultDatabase: nexusai
    editable: true

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# README - DOCUMENTATION MODULE 10
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Module 10 : Analytics & Monitoring

## ğŸ“‹ Vue d'ensemble

Module d'analytics et de monitoring pour NexusAI, fournissant :
- Collecte d'Ã©vÃ©nements utilisateur via Kafka
- Stockage optimisÃ© dans ClickHouse
- MÃ©triques Prometheus
- Dashboards Grafana
- SystÃ¨me d'alerting automatique

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka      â”‚ â† Ã‰vÃ©nements des autres modules
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Collector   â”‚ â†’ Buffer â†’ Batch Insert
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ClickHouse  â”‚ â† Stockage analytics (colonnes)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analytics    â”‚ â†’ API REST
â”‚    API       â”‚ â†’ Prometheus Metrics
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Grafana    â”‚ â† Dashboards & visualisations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ DÃ©marrage rapide

### 1. PrÃ©requis

- Docker & Docker Compose
- Java 21+
- Maven 3.9+

### 2. Lancer l'environnement de dÃ©veloppement

```bash
# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier les logs
docker-compose logs -f analytics-api

# Initialiser les tables ClickHouse
docker-compose exec clickhouse clickhouse-client --multiquery < sql/init-clickhouse.sql
```

### 3. AccÃ¨s aux interfaces

- **Analytics API** : http://localhost:8080
- **Swagger UI** : http://localhost:8080/swagger-ui.html
- **Actuator** : http://localhost:8080/actuator
- **Prometheus** : http://localhost:9090
- **Grafana** : http://localhost:3000 (admin/admin123)
- **Alertmanager** : http://localhost:9093
- **ClickHouse** : http://localhost:8123

## ğŸ“¦ Structure du projet

```
nexusai-analytics/
â”œâ”€â”€ analytics-core/          # ModÃ¨les et services mÃ©tier
â”œâ”€â”€ analytics-api/           # API REST
â”œâ”€â”€ analytics-collector/     # Collecteurs Kafka
â”œâ”€â”€ analytics-reporting/     # GÃ©nÃ©ration de rapports
â”œâ”€â”€ analytics-monitoring/    # MÃ©triques Prometheus
â”œâ”€â”€ sql/                     # Scripts SQL ClickHouse
â”œâ”€â”€ monitoring/              # Config Prometheus/Grafana
â””â”€â”€ docker-compose.yml       # Environnement dev
```

## ğŸ”§ Configuration

### Application (application.yml)

```yaml
spring:
  application:
    name: nexusai-analytics

nexusai:
  analytics:
    collection:
      batch-size: 1000
      batch-timeout: 5000
    retention:
      raw-events: 90      # jours
      aggregated: 365     # jours
```

### Variables d'environnement

```bash
# ClickHouse
CLICKHOUSE_URL=jdbc:clickhouse://localhost:8123/nexusai
CLICKHOUSE_USER=nexusai
CLICKHOUSE_PASSWORD=nexusai123

# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
```

## ğŸ“Š APIs principales

### Ã‰vÃ©nements

```bash
# Enregistrer un Ã©vÃ©nement
POST /api/v1/analytics/events
{
  "userId": "uuid",
  "eventType": "page_view",
  "eventData": {...}
}

# RÃ©cupÃ©rer les Ã©vÃ©nements d'un utilisateur
GET /api/v1/analytics/events/user/{userId}?startTime=...&endTime=...

# Statistiques
GET /api/v1/analytics/events/stats
```

### MÃ©triques

```bash
# Enregistrer une mÃ©trique
POST /api/v1/analytics/metrics
{
  "metricName": "cpu_usage",
  "metricValue": 45.2,
  "serviceName": "user-service"
}

# Statistiques d'une mÃ©trique
GET /api/v1/analytics/metrics/{metricName}/stats

# MÃ©triques agrÃ©gÃ©es
GET /api/v1/analytics/metrics/{metricName}/aggregate?period=HOUR
```

## ğŸ“ˆ MÃ©triques Prometheus

MÃ©triques exposÃ©es :
- `nexusai_events_processed_total` : Ã‰vÃ©nements traitÃ©s
- `nexusai_events_failed_total` : Ã‰vÃ©nements en erreur
- `nexusai_events_buffer_size` : Taille du buffer
- `nexusai_collection_duration_seconds` : DurÃ©e de collecte
- `nexusai_aggregation_duration_seconds` : DurÃ©e d'agrÃ©gation

## ğŸ¯ RÃ©partition des tÃ¢ches

### Ã‰quipe 1 : Core & Services
- ModÃ¨les de donnÃ©es
- Services mÃ©tier (EventService, MetricService)
- Repositories ClickHouse

### Ã‰quipe 2 : API REST
- Controllers
- DTOs
- Documentation Swagger
- Tests E2E

### Ã‰quipe 3 : Collector
- Kafka listeners
- Buffers batch
- Gestion erreurs

### Ã‰quipe 4 : Monitoring
- MÃ©triques Prometheus
- Health indicators
- SystÃ¨me d'alerting
- Dashboards Grafana

## ğŸ§ª Tests

```bash
# Tests unitaires
mvn test

# Tests d'intÃ©gration
mvn verify -P integration-tests

# Coverage
mvn jacoco:report
```

## ğŸ“š Documentation complÃ©mentaire

- [Architecture dÃ©taillÃ©e](docs/architecture.md)
- [Guide de contribution](docs/CONTRIBUTING.md)
- [API Reference](http://localhost:8080/swagger-ui.html)

## ğŸ‘¥ Ã‰quipe

**Ã‰quipe Analytics - Module 10**
- Sous-Ã©quipe Core
- Sous-Ã©quipe API
- Sous-Ã©quipe Collector
- Sous-Ã©quipe Monitoring
